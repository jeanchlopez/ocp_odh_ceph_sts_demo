{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user2 can access dataset owned by user1 via AssumeRole Ceph STS Feature (without credentials sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "## User2 has to add the ARN value of the role created by user1\n",
    "\n",
    "Role_Arn = 'arn:aws:iam::odh:role/S3Access2'\n",
    "endpoint_url='10.0.111.122:8080'\n",
    "\n",
    "user2_sts = boto3.client('sts',\n",
    "           aws_access_key_id='user2',\n",
    "           aws_secret_access_key='user2pass',\n",
    "           endpoint_url= \"http://\"+ endpoint_url ,\n",
    "           region_name='')\n",
    "\n",
    "\n",
    "response = user2_sts.assume_role(\n",
    "            RoleArn=Role_Arn,\n",
    "            RoleSessionName='user2',\n",
    "            DurationSeconds=3600\n",
    "            )\n",
    "\n",
    "\n",
    "aws_access_key_id = response['Credentials']['AccessKeyId']\n",
    "aws_secret_access_key = response['Credentials']['SecretAccessKey']\n",
    "\n",
    "\n",
    "s3client = boto3.client('s3',\n",
    "            aws_access_key_id = response['Credentials']['AccessKeyId'],\n",
    "            aws_secret_access_key = response['Credentials']['SecretAccessKey'],\n",
    "            aws_session_token = response['Credentials']['SessionToken'],\n",
    "            endpoint_url= \"http://\"+ endpoint_url ,\n",
    "            region_name='',)\n",
    "\n",
    "bucket_name = 'ufo-dataset'\n",
    "#s3bucket = s3client.create_bucket(Bucket=bucket_name)\n",
    "#print(s3client.list_buckets())\n",
    "\n",
    "print(\"Getting dataset from user1 \"+ bucket_name +\" bucket, without sharing credentials \\n\")\n",
    "for key in s3client.list_objects(Bucket=bucket_name)['Contents']:\n",
    "    print(\"File Found : \"+key['Key'])\n",
    "    \n",
    "#print(\"\\n Creating a new bucket from odh2user1 account\")\n",
    "#try:\n",
    "#    s3bucket = s3client.create_bucket(Bucket='odh2user1-bucket')\n",
    "#except ClientError as e:\n",
    "#    print(\"\\n Bucket already exists \\n\")\n",
    "\n",
    "# Retrieve the list of existing buckets\n",
    "#response = s3client.list_buckets()\n",
    "\n",
    "# Output the bucket names\n",
    "#print('Existing buckets:')\n",
    "#for bucket in response['Buckets']:\n",
    "#    print(f'  {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating if user2 can access dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import os\n",
    "import socket\n",
    "\n",
    "# create a spark session\n",
    "spark_cluster_url = f\"spark://{os.environ['SPARK_CLUSTER']}:7077\"\n",
    "spark = SparkSession.builder.master(spark_cluster_url).getOrCreate()\n",
    "\n",
    "# test your spark connection\n",
    "spark.range(5, numPartitions=5).rdd.map(lambda x: socket.gethostname()).distinct().collect()\n",
    "\n",
    "hadoopConf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "hadoopConf.set(\"fs.s3a.endpoint\", endpoint_url)\n",
    "hadoopConf.set(\"fs.s3a.access.key\", aws_access_key_id)\n",
    "hadoopConf.set(\"fs.s3a.secret.key\", aws_secret_access_key)\n",
    "hadoopConf.set(\"fs.s3a.path.style.access\", \"false\")\n",
    "hadoopConf.set(\"fs.s3a.connection.ssl.enabled\", \"false\") # false if not https\n",
    "\n",
    "data = spark.read.csv('s3a://ufo-dataset/UFO_dataset_kaggle.csv', sep=\",\", header=True)\n",
    "\n",
    "df = data.toPandas()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyspark\n",
    "!{sys.executable} -m pip install boto\n",
    "!{sys.executable} -m pip install plotly\n",
    "!{sys.executable} -m pip install plotly --upgrade\n",
    "!{sys.executable} -m pip install chart_studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 1 : What are the TOP-5 countries which reported UFO sighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = data.groupBy(\"country\").count().toPandas()\n",
    "\n",
    "import chart_studio\n",
    "chart_studio.tools.set_credentials_file(username='karasing', api_key='4VVeR6dmEYoZwBwPi6hV')\n",
    "\n",
    "#import plotly \n",
    "#plotly.tools.set_credentials_file(username='karasing', api_key='')\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "data1 = [go.Bar(\n",
    "    x=plot1['country'],\n",
    "    y=plot1['count'],\n",
    "    width = 0.8 \n",
    ")]\n",
    "py.iplot(data1, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 2 : Which are the TOP-20 cities which reported UFO sighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2 = data.groupBy(\"city\").count().orderBy(data.city.desc()).toPandas()\n",
    "plot2 = plot2.sort_values(by=['count'],ascending=False).head(20)\n",
    "data2 = [go.Bar(\n",
    "    x=plot2['city'],\n",
    "    y=plot2['count'], \n",
    ")]\n",
    "py.iplot(data2, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 3 : How does a UFO Look Like ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3 = data.groupBy(\"shape\").count().orderBy(data.shape.desc()).toPandas()\n",
    "plot3 = plot3.sort_values(by=['count'],ascending=False).head(20)\n",
    "data3 = [go.Bar(\n",
    "    x=plot3['shape'],\n",
    "    y=plot3['count']\n",
    ")]\n",
    "py.iplot(data3, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question - 4 : Which are the TOP-10 cities reporting UFO as \"Light\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "import pandas as pd\n",
    "plot4 = data.groupBy(\"city\",\"shape\").count().filter(data.shape == 'light').sort(desc(\"count\")).toPandas().head(10)\n",
    "data4 = [go.Bar(\n",
    "    x=plot4['city'],\n",
    "    y=plot4['count']\n",
    ")]\n",
    "py.iplot(data4, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
